# Evaluation Metrics

## Evaluation Metrics in Weave
In Weave, Scorers are tools that help you evaluate the outputs from your AI system. They take the AI's output, analyze it, and return a dictionary with the results. Scorers can also look at parts of your input data and provide extra information, like explanations of their evaluations.

You use Scorers when creating a `weave.Evaluation object`. There are two main types of Scorers:

1. Function-based Scorers: Simple Python functions decorated with @weave.op.
2. Class-based Scorers: Python classes that inherit from weave.Scorer for more complex evaluations.

## Function-based Scorers
These are straightforward functions that return a dictionary. They're great for simple evaluations.

```python
@weave.op
def evaluate_uppercase(text: str):
    return  {"text_is_uppercase": text.isupper()}

eval = weave.Evaluations(..., scorers=[evaluate_uppercase])
```

In this example, evaluate_uppercase checks if the text is all uppercase.

## Class-based Scorers
For more advanced evaluations, especially when you need to keep track of additional information or make multiple function calls, you can create a Scorer class.

**Requirements:**
- Inherit from weave.Scorer.
- Define a score method decorated with @weave.op.
- The score method must return a dictionary.

Example:


```python
from weave import Scorer

class SummarizationScorer(Scorer):
    model_id : "the LLM model to use"

    @weave.op
    def score(output, text)
        '''
            output: The summary generated by an AI system
            text: The original text being summarised
        '''
        ...  # evaluate the quality of the summary

summarization_scorer = SummarizationScorer(model_id="o2")
eval = weave.Evaluations(..., scorers=[summarization_scorer])
```
This class evaluates how good a summary is by comparing it to the original text.

## How Scorers Work
### Using Keyword Arguments
Scorers can access both the output from your AI system and the input data.

- **Output:** Include an `output` parameter in your scorer function's signature to access the AI system's output.

- **Input:** Add parameters that match the names of the columns in your dataset to access input data.

For example, if your dataset has a "news_article" column, you can access it in the scorer by adding a `news_article` parameter to your scorer's signature.

### Mapping Column Names
Sometimes, the scorer's parameter names don't match the column names in your dataset. You can fix this using a `column_map`.

If you're using a class-based scorer, pass a dictionary to the `column_map` attribute when you create the scorer. This dictionary maps your scorer's parameter names to the dataset's column names, in the order: `{scorer keyword argument : dataset column name}`.

Example:

```python
from weave import Scorer

# A dataset with news articles to be summarised
dataset = [
    {"news_article": "The news today was great...", "date": "2030-04-20", "source": "Bright Sky Network"}
    ...
]

# Scorer class
class SummarizationScorer(Scorer)
    
    @weave.op
    def score(output, text)
        """
            output: output summary from a LLM summarization system
            text: the text being summarised
        """
        ...  # evaluate the quality of the summary

# create a scorer with a column map
scorer = SummarizationScorer(column_map = {"text" : "news_article"})
```
Here, the text parameter in the score method will receive data from the `news_article` column.


In this case, weave Evaluations will automatically pass the output of the LLM summarization system to the `output` parameter in the `score` function and will also extract the value for the `news_article` key in the input dataset row and pass it to the `text` parameter in the scorer.


##nExamples of Scorers

LLM-Powered Evaluators

### `HallucinationFreeScorer`
This scorer checks if your AI system's output includes any hallucinations based on the input data.

**Notes:**
- Customize the `system_prompt` and `user_prompt` attributes to define what "hallucination" means for you.
- This scorer uses the `InstructorLLMScorer` class, so you'll need to install the `instructor` Python package.
- The `score` method expects an input column named `context`. If your dataset uses a different name, use the `column_map` attribute to map `context` to the dataset column.

## `SummarizationScorer`
This scorer evaluates summaries in two ways:

1. **Entity Density:** Checks the ratio of unique entities (like names, places, or things) mentioned in the summary to the total word summary count in order to estimate the "information density" of the summary. Uses an LLM to extract the entities.

2. **Quality Grading:** Uses an LLM-evaluator to grade the summary as `poor`, `ok`, or `excellent`. These grades are converted to scores (0.0 for poor, 0.5 for ok, and 1.0 for excellent) so you can calculate averages.

**Customization:**
- Adjust `summarization_evaluation_system_prompt` and `summarization_evaluation_prompt` to define what makes a good summary.

**Notes:**
- This scorer uses the `InstructorLLMScorer` class.
- The `score` method expects the original text that was summarized to be present in the `input` column of the dataset. Use the `column_map` class attribute to map `input` to the correct dataset column if needed.


TODO:


- Why use Scorers (re-use?) - you want a class not a function
- Explain columm_map
    only during Evaluation call

    output - output of predict

    column_map: A `scorer parameter name : dataset column name` mapping.
    
    This summarization scorer expects the input column in the dataset to be named "input" \
        and the output column in the dataset to be named "summary".
        You can specify a different mapping in the `column_map` argument. For example, \
        if your dataset contains columns "news_article" and "news_summary" then you can \
        specify `column_map={"input": "news_article", "output": "news_summary"}`. show explicit mapping in the `score` as an example

## LLM-powered Evaluators

### HallucinationFreeScorer

A Scorer that uses an LLM to determine if the model output contains any hallucinations
based on the input data.

Note:
    - The meaning of "hallucination" can vary from person to person, you will likely want to 
    customize the `system_prompt` and `user_prompt` to fit your specific needs.
    - This Scorer uses the `InstructorLLMScorer` class to generate structured outputs from the LLM 
    provider's response; you will have to install the `instructor` python package to use it.
    - The `score` method expects the input column from the dataset to be named "context". It will use
    this data as the ground-truth to check hallucinations against. If your dataset column has a 
    different name, you can specify a different mapping using the `column_map` argument in the init 
    of HallucinationFreeScorer by passing `column_map={"context": "context"}`.

Attributes:
    system_prompt (str): The prompt describing the task, defines what a "hallucination" is.
    user_prompt (str): The string template to pass the input and output data. The template must 
    contain placeholders for both `{input_data}` and `{output}`.
    model_id (str): The LLM model name, depends on the LLM's providers to be used `client` being used.
    temperature (float): LLM temperature setting.
    max_tokens (int): Maximum number of tokens in the LLM's response.

Methods:
    score(output: str, context: str) -> HallucinationResponse:
        Analyzes the output to detect hallucinations based on the given context.

### SummarizationScorer

A Scorer that evaluates the quality of summaries in two ways:
    - using an LLM to calculate the entity density of the summary, similar to how entity density is
    used in the Chain of Density paper, https://arxiv.org/abs/2309.04269. This is a rough measure for
    how information-dense the summary is.
    - using another LLM evaluator to grade the summary quality from `poor`, `ok`, to `excellent`. These
    grades are then mapped to numerical scores, {`poor`: 0.0, `ok`: 0.5, `excellent`: 1.0}, in order to
    be able to calculate an average score across a dataset of summaries if needed.

To customise the LLM evaluator you can customise the `summarization_evaluation_system_prompt`and
`summarization_evaluation_prompt` attributes to be tailored your specific definition of what a good summary
should look like.

Note:
    - This Scorer uses the `InstructorLLMScorer` class to generate structured outputs from the LLM 
    provider's response; you will have to install the `instructor` python package to use it.
    - The `score` method expects the input column from the dataset to be named "input". If your dataset
    column has a different name, you can specify a different mapping using the `column_map` argument in the 
    init of SummarizationScorer by passing `column_map={"input": "news_article"}`.

Attributes:
    extraction_system_prompt (str): System prompt to extract the distinct entities in the input. Customising 
    this can help ensure that the LLM identifies the `entities` that you care about.
    extraction_prompt (str): Prompt template for entity extraction; must contain a `{text}` placeholder.
    summarization_evaluation_system_prompt (str): System prompt defining how to evaluate the quality of a summary.
        Asks an LLM to grade the summary from `poor`, `ok`, to `excellent` and provide a rationale for the grade.
    summarization_evaluation_prompt (str): Prompt template for summarization evaluation instruction; must contain 
        `{input}` and `{summary}` placeholders. 
    entity_density_threshold (float): Threshold for determining if a summary is sufficiently entity-dense.
    model_id (str): The LLM model name, depends on the LLM's providers to be used `client` being used.
    temperature (float): LLM temperature setting.
    max_tokens (int): Maximum number of tokens in the LLM's response.

Methods:
    extract_entities(text: str) -> List[str]:
        Uses an LLM to extract unique entities from the text.

    evaluate_summary(input: str, summary: str) -> SummarizationEvaluationResponse:
        Evaluates the quality of a summary using an LLM.

    score(input: str, output: str, **kwargs: Any) -> dict:
        Calculates summarization score and entity density score for the given input and output.


## Programmatic Evaluators

### ValidJSONScorer

Validate whether a string is valid JSON.

```
from weave.scorers import ValidJSONScorer
```